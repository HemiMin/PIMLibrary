#ifndef _FIM_RELU_KERNELS_FIMK_
#define _FIM_RELU_KERNELS_FIMK_

#define PARK_IN 1
#define CHANGE_SB_HAB 1
#define PROGRAM_CRF 1
#define CHANGE_HAB_HABFIM 1
#define COMPUTE_RELU 1
#define CHANGE_HABFIM_HAB 1
#define CHANGE_HAB_SB 1
#define PARK_OUT 1

__global__ void relu_fim(volatile uint8_t* __restrict__ fim_data, volatile uint8_t* __restrict__ fim_ctr,
                         volatile uint8_t* __restrict__ output, int size,
#ifdef EMULATOR
                         FimMemTraceData* fmtd16, int* frd_size, int mt_width,
#endif
                         uint8_t* crf_binary, int crf_size)
{
#ifdef EMULATOR
    g_fba = (uint64_t)fim_ctr;
    g_fmtd16 = fmtd16;
    g_ridx[hipBlockIdx_x] = 0;
    m_width = mt_width;
    __syncthreads();
#endif
    int trans_size = 32;
    int num_col = 32;
    int num_fim_blocks = 8;
    int num_fim_chan = 64;
    int num_grf = 8;
    int num_ba = 4;
    int out_dim = size / trans_size;
    int num_tile = out_dim / (num_fim_blocks * num_fim_chan * num_grf) / 2;

    int gidx = hipThreadIdx_x / 2;
    uint64_t offset = (hipThreadIdx_x % 2) * 0x10;
    uint64_t addr, addr_even, addr_odd;

    /* Radeon7(VEGA20) memory is 16GB but our target is 32GB system */
    /* so program_crf and chagne_fim_mode functions can not access to over 8GB in our system */

#if PARK_IN
    addr = addr_gen(hipBlockIdx_x, 0, gidx / num_ba, gidx % num_ba, (1 << 13), 0);
    W_CMD(&fim_ctr[addr + offset]);
    B_CMD(1);
#endif

    if (hipThreadIdx_x < 2) {
#if CHANGE_SB_HAB
        addr = addr_gen(hipBlockIdx_x, 0, 2, 0, 0x27ff, 0x1f);
        W_CMD(&fim_ctr[addr + offset]);
        B_CMD(1);
        addr = addr_gen(hipBlockIdx_x, 0, 2, 1, 0x27ff, 0x1f);
        W_CMD(&fim_ctr[addr + offset]);
        B_CMD(1);
        addr = addr_gen(hipBlockIdx_x, 0, 0, 0, 0x27ff, 0x1f);
        W_CMD(&fim_ctr[addr + offset]);
        B_CMD(1);
        addr = addr_gen(hipBlockIdx_x, 0, 0, 1, 0x27ff, 0x1f);
        W_CMD(&fim_ctr[addr + offset]);
        B_CMD(1);
#endif
#if PROGRAM_CRF
        addr = addr_gen(hipBlockIdx_x, 0, 0, 1, 0x3fff, 0x4 + gidx);
        W_CMD_R(&fim_ctr[addr + offset], crf_binary + (hipThreadIdx_x << 4));
#endif
#if CHANGE_HAB_HABFIM
        addr = addr_gen(hipBlockIdx_x, 0, 0, 0, 0x3fff, 0x0);
        W_CMD_R(&fim_ctr[addr + offset], elt_add_hab_to_hab_fim + offset);
        R_CMD(&fim_ctr[addr + offset]);
#endif
        B_CMD(1);
    }

#if COMPUTE_RELU
    if (hipThreadIdx_x < 16) {
        for (int tile_idx = 0; tile_idx < num_tile; tile_idx++) {
            unsigned int loc = tile_idx * num_grf + gidx;
            unsigned int row = loc / num_col;
            unsigned int col = loc % num_col;

            addr = addr_gen(hipBlockIdx_x, 0, 0, 0, row, col);
            addr_even = addr + offset;
            addr_odd = addr_even + 0x2000;

            R_CMD(&fim_data[addr_even]);
            B_CMD(1);

            W_CMD(&output[addr_even]);
            R_CMD(&output[addr_even]);
            B_CMD(1);

            R_CMD(&fim_data[addr_odd]);
            B_CMD(1);

            W_CMD(&output[addr_odd]);
            R_CMD(&output[addr_odd]);
            B_CMD(1);
        }
    }
#endif

    if (hipThreadIdx_x < 4) {
#if CHANGE_HABFIM_HAB
        addr = addr_gen(hipBlockIdx_x, 0, 0, 0, 0x3fff, 0x0);
        W_CMD_R(&fim_ctr[addr + offset], elt_add_hab_fim_to_hab + offset);
        R_CMD(&fim_ctr[addr + offset]);
        B_CMD(1);
#endif
#if CHANGE_HAB_SB
        addr = addr_gen(hipBlockIdx_x, 0, 0, gidx, 0x2fff, 0x1f);
        W_CMD(&fim_ctr[addr + offset]);
        R_CMD(&fim_ctr[addr + offset]);
        B_CMD(1);
#endif
    }

#if PARK_OUT
    addr = addr_gen(hipBlockIdx_x, 0, gidx / num_ba, gidx % num_ba, (1 << 13), 0);
    W_CMD(&fim_ctr[addr + offset]);
#endif

#ifdef EMULATOR
    if (hipBlockIdx_x == 0 && hipThreadIdx_x == 0) {
        frd_size[0] = g_ridx[0];
    }
#endif
}

#endif /* _FIM_RELU_KERNELS_FIMK_ */
