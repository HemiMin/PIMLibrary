#ifndef _GPU_CUSTOM_GEMV_KERN_
#define _GPU_CUSTOM_GEMV_KERN_

template <typename U, typename V, typename W>
void rocblas_gemv_template_Axy(hipStream_t p_stream, const V *A, const V *x, W *y, int m, int n, int k, U alpha,
                               U beta);

template <typename U, typename V, typename W>
void rocblas_gemv_template_xAy(hipStream_t p_stream, const V *x, const V *A, W *y, int m, int n, int k, U alpha,
                               U beta);

void rocblas_gemv_fp16_xAy(void *x, void *A, void *y, int m, int n, int k, float alpha, float beta, hipStream_t stream)
{
    rocblas_gemv_template_xAy(stream, reinterpret_cast<_Float16 *>(x), reinterpret_cast<_Float16 *>(A),
                              reinterpret_cast<_Float16 *>(y), m, n, k, alpha, beta);
}

void rocblas_gemv_fp16_Axy(void *A, void *x, void *y, int m, int n, int k, float alpha, float beta, hipStream_t stream)
{
    rocblas_gemv_template_Axy(stream, reinterpret_cast<_Float16 *>(A), reinterpret_cast<_Float16 *>(x),
                              reinterpret_cast<_Float16 *>(y), m, n, k, alpha, beta);
}

template <int NB_X, typename T, typename U>
__device__ void gemvt_kernel_calc_xAy(int m, int n, U alpha, const T *x, int lda, const T *A, int incx, U beta, T *y)
{
  // m = wt.h
  // n = wt.w
  // x = in
  // lda = wt.h 
  // A = mat(wt)
  // incx = wt.w
  // y = out

    int tx = hipThreadIdx_x;

    if (tx < m) A += tx * incx;

    U res;
    res = 0.0;

    int col = 0;
    __shared__ U sdata[NB_X];

    // partial sums
    int m_full = (m / NB_X) * NB_X;
    // m_full = (wt.h/256) * 256

    for (int i = 0; i < m_full; i += NB_X) res += x[i + tx] * A[i * incx];

    if (tx + m_full < m) res += x[m_full + tx] * A[m_full * incx];

    sdata[tx] = res;

    // tree reduction of partial sums,
    if (NB_X > 16) {
        rocblas_sum_reduce<NB_X>(tx, sdata);
    } else {
        __syncthreads();

        if (tx == 0) {
            for (int i = 1; i < m && i < NB_X; i++) sdata[0] += sdata[i];
        }

        __syncthreads();
    }

    if (tx == 0) {
        if (beta != 0) {
            y[col] = alpha * sdata[0] + beta * y[col];
        } else {
            y[col] = alpha * sdata[0];
        }
    }
}

template <int NB_X, typename U, typename V, typename W>
__global__ void gemvt_kernel_xAy(int m, int n, U alpha_device_host, const V *xa, int lda, const V *Aa, int incx,
                                 U beta_device_host, W *ya)
{
    const V *x = xa;
    const V *A = Aa + hipBlockIdx_y;
    W *y = ya + hipBlockIdx_y;

    auto alpha = alpha_device_host;
    auto beta = beta_device_host;
    // NB_X == 256
    gemvt_kernel_calc_xAy<NB_X>(m, n, alpha, x, lda, A, incx, beta, y);
}

template <typename U, typename V, typename W>
void rocblas_gemv_template_xAy(hipStream_t p_stream, const V *x, const V *A, W *y, int m, int n, int k, U alpha, U beta)
{
    if (m != 1) {
        return;
    }
    static constexpr int NB = 256;
    dim3 gemvt_grid(1, n);
    dim3 gemvt_threads(NB);

    hipLaunchKernelGGL((gemvt_kernel_xAy<NB>), gemvt_grid, gemvt_threads, 0, p_stream, k, n, alpha,
                       x,  // k
                       k,
                       A,  // kxn
                       n, beta, y);
}

// Ax = y
template <int NB_X, typename T, typename U>
__device__ void gemvt_kernel_calc_Axy(int m, int n, U alpha, const T *A, int lda, const T *x, int incx, U beta, T *y)
{
    int tx = hipThreadIdx_x;
    if (tx < n) A += tx;

    U res;
    res = 0.0;

    int col = 0;
    __shared__ U sdata[NB_X];

    // partial sums
    int m_full = (n / NB_X) * NB_X;

    for (int i = 0; i < m_full; i += NB_X) res += A[i] * x[(tx + i) * incx];

    if (tx + m_full < n) res += A[m_full] * x[(tx + m_full) * incx];

    sdata[tx] = res;

    // tree reduction of partial sums,
    if (NB_X > 16) {
        rocblas_sum_reduce<NB_X>(tx, sdata);
    } else {
        __syncthreads();

        if (tx == 0) {
            for (int i = 1; i < n && i < NB_X; i++) sdata[0] += sdata[i];
        }

        __syncthreads();
    }

    if (tx == 0) {
        if (beta != 0) {
            y[col] = alpha * sdata[0] + beta * y[col];
        } else {
            y[col] = alpha * sdata[0];
        }
    }
}

template <int NB_X, typename U, typename V, typename W>
__global__ void gemvt_kernel_Axy(int m, int n, U alpha_device_host, const V *Aa, int lda, const V *xa, int incx,
                                 U beta_device_host, W *ya)
{
    const V *A = Aa + hipBlockIdx_y * n;
    const V *x = xa;
    W *y = ya + hipBlockIdx_y;

    auto alpha = alpha_device_host;
    auto beta = beta_device_host;
    gemvt_kernel_calc_Axy<NB_X>(m, n, alpha, A, lda, x, incx, beta, y);
}

template <typename U, typename V, typename W>
void rocblas_gemv_template_Axy(hipStream_t p_stream, const V *A, const V *x, W *y, int m, int n, int k, U alpha, U beta)
{
    if (n != 1) {
        return;
    }
    static constexpr int NB = 128;
    dim3 gemvt_grid(1, m);
    dim3 gemvt_threads(NB);

    hipLaunchKernelGGL((gemvt_kernel_Axy<NB>), gemvt_grid, gemvt_threads, 0, p_stream, m, k, alpha,
                       A,  // k
                       k,
                       x,  // kxn
                       n, beta, y);
}

#endif /* _GPU_CUSTOM_GEMV_KERN_ */
